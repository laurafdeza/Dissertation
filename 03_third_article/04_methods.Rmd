# 4. Methods 
## 4.1. Participants
The participants were 29 monolingual speakers of Spanish (SS, females = 19), 61 L1 English-L2 Spanish speakers (females = 44), and 63 L1 Mandarin Chinese-L2 Spanish speakers (females = 22). 
Data from one monolingual participant was removed because of task malfunction.
All participants were between 18-45 years of age, right-handed, had corrected-to-normal vision, and high school education or above. 
All participants grew up in monolingual L1 communities and were living in Spain at the time of data collection. 
The L1 Spanish speakers were native to Madrid, Spain.
They had learned some English in school but did not speak it fluently.
They had not lived in non-Spanish or non-monolingual Spanish communities.
The English and Chinese speakers were late learners of Spanish.
Their proficiency ranged from intermediate to highly advanced.
They were comparable in L2 proficiency *t*(121.54) = -0.143, *p* = 0.887, L2 use *t*(118.47) = -1.962, *p* = 0.052, and months living in Spain *t*(116.47) = -0.377, *p* = 0.707, as shown by two one-sided tests of equivalence (see Table 1 for demographic information).


TABLE 1



## 4.2. Materials
Participants completed five tasks.

### 4.2.1. Spanish proficiency test (only L2 speakers).
An 56-question adapted version of the *Diploma de Español como Lengua Extranjera* ('Certificate of Spanish as a Foreign Language', by Instituto Cervantes) was administered via Qualtrics to assess Spanish grammar and vocabulary knowledge [@sagarra2010role].

### 4.2.2. Background questionnaire.
This questionnaire gathered information about participants' age, handedness, languages spoken currently and while growing up, age of acquisition, time spent living abroad, Spanish use patterns, driving skills, sports played, for how long and expertise.

### 4.2.3. Eye-tracking prediction task.
A visual-world paradigm with two options was used to measure participants' abilities to use the first syllable's stress in disyllabic verbs to predict the verbs' suffixes before hearing them.
The eye-tracker was an EyeLink 1000 Plus desktop mount from SR Research (sampling rate: 1k Hz; spatial resolution of .32o horizontal and .25o vertical; averaged calibration error: .25o-.5o). 
The task was programmed and delivered with SR Research’s Experiment Builder software; data was extracted with SR Research’s Data Viewer software. 
Tracking was monocular (right eye) and followed cyclopean extraction mode. 
We set a velocity threshold of 50 °/sec to isolate fixations. 
Shorter eye movements taking place during fixations (e.g., tremors, drifts, and microsaccades) were considered part of the fixation because numerous studies show that they often mean little in higher-level analyses (e.g., _Ditchburn, 1980_). 
We used a BenQ XL2420TE display monitor at a resolution of 1920 x 1080 pixels, and Sol Republic 1601-32 headphones. 

There were 100 sentences: 4 practice sentences, 16 experimental sentences, and 80 fillers. 
The practice sentences appeared in the same order for all participants. 
The filler and experimental sentences were distributed into 8 blocks following a Latin square design. 
Each block contained 2 experimental sentences, one per condition, and 6 filler sentences. 
Sentences were randomized between blocks and pseudo-randomized within blocks to avoid two experimental sentences of the same condition appearing consecutively. 
All sentences were recorded using a Fostex DC-R302 digital recorder and a Shure SM10A head-mounted microphone in a Whisper room 6084 E sound booth at a sampling rate of 44.1 kHz and 16-bit quantization. 
A Castilian Spanish female speaker unaware of the purpose of the study recorded all the sentences three times in three different pseudo-randomized orders, and the clearest pair of the three repetitions was chosen. 
She was instructed to use a standard intonation, and a consistent rate that resulted in sentences of 4.37 (SD = 0.68) syllables per second and 4.17 (SD = 1.14) seconds per sentence.
The intensity of the sentences was normalized to ~75dB and 100 ms of leading and trailing silence were added using Praat _(Boersma & Weenink, 2021)_.

All sentences were grammatical. 
Experimental sentences were 5 words long and followed a SVO word order.
Subjects were animate nouns, and objects were inanimate nouns. 
Both were 2-4 syllables long. 
Experimental verbs were disyllabic third-person singular regular transitive -ar verbs with a CVC-CV syllabic structure. 
Each experimental sentence had two conditions: present (paroxytone) and preterite (oxytone; e.g., *El ladrón salta/saltó la valla* ‘the thief jumps/jumped over the fence’). 
The visual stimuli consisted of a present and a preterite verb displayed side by side on the screen. 
Present verbs appeared on the left in half of the trials and on the right in the other half. 
Images of words rather than objects were used because it is difficult to illustrate present and past actions, it is uncertain what word participants truly activate when they see an object, and phonological competitor effects are stronger with words than pictures (Huettig & McQueen, 2007; Ito, Dunn, & Pickerin, 2017). 
Filler sentences contained anaphoras, gender agreement and idiomatic expressions and were between 5 and 14 words long. 
The written words for the filler sentences consisted of inanimate nouns for the anaphora fillers, descriptive adjectives for the gender agreement fillers, and ending nouns for the idiomatic fillers.

#### 4.2.4. Visuospatial anticipation task
An adapted version of the ZBA task [*Zeit- und Bewegungsantizipation* 'Time and Movement Anticipation,' Schuhfried Wiener Testsystem; @vienna2013time] was employed to measure visual-spatial predictive abilities.
The task was created and administered in PsychoPy v3.2. [@peirce2019psychopy2] using the same monitor as above.

In this task, a car on the screen moved from left to right or right to left at three different speeds: low (3.342 cm/s), medium (5.160 cm/s), and fast (7.087 cm/s).
The car then disappeared behind a mountain. 
The participants had to gauge when the car should reappear from the other side of the mountain, marked with a checkered flag, based on the size of the mountain and the speed of the car.
When they thought the car should reappear, participants pressed the spacebar.
The trial ended automatically at key press, and the following trial started.

There were four practice trials and 48 experimental trials.
The speed in the practice trials was set at either 4 cm/s or 6 cm/s, and the car moved in an opposite direction in each of the two trials for each speed.
In the experimental trials, there were 8 trials for each speed and direction. 
Trials were pseudo-randomized so that no two trials with the exact same condition (same speed and same direction) appeared in a row.

### 4.2.3.2. Visuospatial WM task
An adapted version of [@milner1971interhemispheric]'s Corsi-blocks tapping test served to assess visuospatial WM.
The task was again created and administered in PsychoPy v3.2. [@peirce2019psychopy2] using the same monitor as in the previous tasks.

In each trial, participants saw a grid of 4 x 4 empty squares on a white background. 
Some of the squares would flash red for 1 s and then turn white again creating a sequence of flashes. 
Participants had to recreate the sequence of flashed squares.
There were no time constraints.
The following trial started once the participant clicked the same number of squares as those contained in the sequence.

There were two practice sequences, and 21 experimental sequences split into sets of three.
The first experimental set started with sequences of 3 squares.
Then, a new set of three sequences one square longer started.
The longer trials had sequences of 9 squares. 
The sequences were random.


## 4.3. Procedure
Data collection took place in a single session of about 1 hour and 30 minutes.
The experiment was conducted in Spanish, although written instructions were provided in the participants' L1.
Participants completed the tasks in this order: Spanish proficiency test, background questionnaire, eye-tracking prediction task, visuospatial anticipation task, and Corsi-blocks task.

### 4.3.1. Eye-tracking prediction task. 
Participants were randomly assigned to one of two versions of the task.
Each version contained only one of the two conditions for a verb (e.g., if *salta* “s/he jumps” (present/paroxytone) appeared in version 1, then version 2 contained *saltó* “s/he jumped” (preterite/oxytone)).
Both versions had the same practice trials, and the same number of filler and experimental trials.

For the task, participants rested their head on a chin rest, completed a 9-point grid calibration task, and received task instructions. 
Then, participants completed the practice trials and asked questions. 
Next, they completed the experimental trials. 
For each trial, participants saw a drift correction sign, a + fixation sign for 250ms, two verbs side by side for 1,000 ms, listened to the sentence, and chose the verb on the screen they heard as soon as possible by pressing the left- or right-shift key. 
Upon pressing, a rectangle appeared around the selected verb. 
No feedback was provided. 
Response recording was set up to be registered only when the key press happened at or after the onset of the verb. 
Key presses did not stop the sound file. 
After the sentence, there was a 500 ms blank screen, and the next trial began. 
Figure 1 illustrates a sample trial.

```{r knitr, include=TRUE, echo=FALSE, fig.cap = 'Sample trial of the eye-tracking prediction task'}
knitr::include_graphics('../00_intro/figs/vwp.png', dpi = 108)
```

### 4.3.2. Visuospatial anticipation task. 
Participants first received the instructions for the task, completed the two practice trials and asked questions about the procedure.
In the practice trials, participants saw the car's position upon pressing the spacebar as feedback in the first two trials, to learn if they had timed the key press correctly with the speed of the car.
In the last two practice trials, they did not receive any feedback or saw the car upon pressing the spacebar, imitating the procedure in the experimental trials. 
In the experimental trials, the trial would automatically finish upon the spacebar press. 
There was a fixation cross for 250 ms between trials. 
Figure 2 shows a trial of the task.

```{r, include=TRUE, echo=FALSE, fig.cap = 'Sample trial of the visuospatial anticipation task'}
knitr::include_graphics('../00_intro/figs/car.png', dpi = 108)
```

### 4.3.3. Visuospatial WM task.
Participants first received instructions, completed two practice sets, and asked questions.
In each trial, both practice and experimental, participants saw flashing squares and recreated the sequences of flashing squares by left-clicking on them with the mouse.
Once they had clicked the same number of squares as in the original sequence, a fixation cross appeared for 500 ms in the center of the screen, and the next trial with a new sequence started.
The task automatically moved to the next set of three sequences one-square longer upon completion of a level (see Figure 3 for a sample trial). 
No feedback was provided throughout the task.

```{r, include=TRUE, echo=FALSE, fig.cap = 'Sample trial of the Corsi-blocks tapping task'}
knitr::include_graphics('../00_intro/figs/corsi.png', dpi = 108)
```


## 4.4. Data analysis
Statistical analyses were conducted on R [@team2013r] with the packages *lme4* [@bates2014fitting].
The gaze fixation data were downsampled to 50 ms bins and incorrect responses were filtered out (0.42% of data).
The data were centered 200 ms after the onset of the last syllable to account for saccade planning and launching, as is standard procedure in auditory eye-tracking studies [e.g., @fischer1992saccadic; @saslow1967effects].

Growth curve analyses [GCA, @mirman2016growth] with mixed-effects were used to analyze the time window around the verb encompassing the departure of looks from chance levels.
The time window spanned from 400 ms before to 200 ms after the center of our data. 
These GCA analyses resulted in 9 different models—three for each L1 population.
One of these models was for visuospatial anticipation abilities, a second one for verbal processing speed, and a third one for visuospatial processing speed.
The L1 populations, visuospatial measures and verbal processing speed were separated to avoid overfitting and to avoid making the results uninterpretable.

Main effects and interactions were assessed by means of nested model comparisons.
We tested linear, quadratic and cubic orthogonal polynomial time terms to model the time course in the GCA.
The outcome data, proportion of fixations on the target at the onset of the last syllable on the verb from the eye-tracking prediction task, was modified using the empirical logic transformation, as it is binary data [fixations on the target or the distractor; @barr2008analyzing].

The three GCA for the monolinguals included lexical stress, the time terms and visuospatial prediction abilities, visuospatial processing speed or verbal processing speed as fixed effects, and participant and item as random intercepts, and lexical stress as random slope.
The GCA for the L2 speakers were modeled with lexical stress, the time terms, L2 proficiency and visuospatial prediction abilities or verbal or visuospatial processing speed as fixed effects, and participant and item as random intercepts, and lexical stress as random slope.
Lexical stress was categorical and contrast-coded.
The continuous variable L2 proficiency was standardized.
Visuospatial prediction abilities values were obtained by calculating the time difference (timing) between participants' key presses and the ms when the car should reappear, and then we estimated a measure of visuospatial anticipation for each participant via the random effects of a separate model estimating key-press time as a function of speed and direction.
That is, individual divergences from the model estimate are taken as an assessment of visualspatial anticipation for subsequent models.
These values could therefore be negative if participants tended to press too soon, or positive if pariticipants tended to wait too long.
Trials where the participant took too long to respond and the car should have 'left' the screen were discarded.
Verbal and visuospatial processing speed values were obtained by measuring the time participants needed in correct trials, and then applying a linear regression to these values where they were the outcome and length of the trial (in terms of words/squares to remember) as predictors, and calculating the random effects for each participant. 
