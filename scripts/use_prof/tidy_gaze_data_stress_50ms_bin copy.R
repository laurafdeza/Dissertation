# Morphosyntactic predictability: tidy stress data ----------------------------
#
# This script will load and tidy the raw eye tracking data
# with 50 ms bins and save the output to data/clean
#
# Last update: 06/11/2019 [working fine]
# Original script by Joseph Casillas
# Adapted to this project by Cristina Lozano-Arg√ºelles
# -----------------------------------------------------------------------------


# Source libs -----------------------------------------------------------------

source(here::here("scripts", "00_load_libs.R"))

# -----------------------------------------------------------------------------
# load data
stress_50 <- read.delim("./data/stress_50bin.txt")

# Check gaze fixation columns have different values
unique(stress_50$AVERAGE_IA_1_SAMPLE_COUNT)  # looking at target according to IA_#_ID
unique(stress_50$AVERAGE_IA_2_SAMPLE_COUNT)  # looking at distractor
unique(stress_50$AVERAGE_IA_0_SAMPLE_COUNT)  # elsewhere


# How much data we lose by selecting only accurate trials overall
sum( ( stress_50$ACCURACY == 0 ) / length( stress_50$ACCURACY ) ) * 100
# 0.4198754

# by stress pattern/tense
pret <- filter(stress_50, cond == 2)
sum( ( pret$ACCURACY == 0 ) / length( pret$ACCURACY ) ) * 100
# 0.06796873

pres <- filter(stress_50, cond == 1)
sum( ( pres$ACCURACY == 0 ) / length( pres$ACCURACY ) ) * 100
# 0.7685756

# by stress pattern/tense and by speaker type
acc_desc <- separate(stress_50, col = RECORDING_SESSION_LABEL,
         into = c("group", "group_member"),
         sep = 3,
         remove = FALSE)

pretmon <- filter(acc_desc, cond == 2 & group == 'mon')
sum( ( pretmon$ACCURACY == 0 ) / length( pretmon$ACCURACY ) ) * 100
# 0.3603604

presmon <- filter(acc_desc, cond == 1 & group == 'mon')
sum( ( presmon$ACCURACY == 0 ) / length( presmon$ACCURACY ) ) * 100
# 0

pretl2 <- filter(acc_desc, cond == 2 & group == 'aes' | group == 'ies')
sum( ( pretl2$ACCURACY == 0 ) / length( pretl2$ACCURACY ) ) * 100
# 0.7661968

presl2 <- filter(acc_desc, cond == 1 & group == 'aes' | group == 'ies')
sum( ( presl2$ACCURACY == 0 ) / length( presl2$ACCURACY ) ) * 100
# 0.7638508

# by speaker type
mon <- filter(acc_desc, group == 'mon')
sum( ( mon$ACCURACY == 0 ) / length( mon$ACCURACY ) ) * 100
# 0.1793154

l2 <- filter(acc_desc, group == 'aes' | group == 'ies')
sum( ( l2$ACCURACY == 0 ) / length( l2$ACCURACY ) ) * 100
# 0.5767546





# Tidy data -------------------------------------------------------------------

# Read data
stress_50 <- stress_50 %>%
  
  # create variable group
  separate(., col = RECORDING_SESSION_LABEL,
           into = c("group", "group_member"),
           sep = 3,
           remove = FALSE) %>%
  
  #select and rename variables of interest
  select(., RECORDING_SESSION_LABEL, TRIAL_INDEX, BIN_INDEX,
         AVERAGE_IA_0_SAMPLE_COUNT, AVERAGE_IA_0_SAMPLE_COUNT_.,
         AVERAGE_IA_1_SAMPLE_COUNT, AVERAGE_IA_1_SAMPLE_COUNT_.,
         AVERAGE_IA_2_SAMPLE_COUNT, AVERAGE_IA_2_SAMPLE_COUNT_.,
         ACCURACY, RT, block, cond, 
         id, lex_freq, phonot_freq, 
         t01, t02, t03, t04, t05, t06, t07, target, version, group) %>%
  dplyr::rename(., participant = RECORDING_SESSION_LABEL,
                trial = TRIAL_INDEX, 
                bin = BIN_INDEX,
                target_count = AVERAGE_IA_1_SAMPLE_COUNT, 
                target_prop = AVERAGE_IA_1_SAMPLE_COUNT_.,
                offset_prev_word = t01,
                onset_v1 = t02,
                onset_c2 = t03,
                onset_c3 = t04,
                onset_v2 = t05,
                offset_target = t06,
                endSentence = t07,
                sentence_id = id) %>%
  
  # remove incorrect
  filter(., ACCURACY == 1) %>%
  
  # drop unused levels of factors
  droplevels(.) %>%

  # Create eLog variable and respective wts
  mutate(.,eLog = log((target_count + 0.5) / (50 - target_count + 0.5)),
         wts = 1 / (target_count + 0.5) + 1 / (50 - target_count + 0.5)) %>%
    
  # Select necessary columns
  # Gather data to prepare for bin adjustment
  # Get suffix onset label and center at 0 for each
  # participant for each item
  dplyr::select(participant, group, target, cond, target, bin,
                target_count, target_prop, eLog, wts, onset_c3) %>%   
  # change onset_v1 in previous line depending on what trigger we want to observe
  gather(., landmark, lm_bin, -c(participant:wts)) %>%
  mutate(., lm_bin = (lm_bin / 50) %>% ceiling(.),
         t_onset = if_else(bin == lm_bin, TRUE, FALSE)) %>%
  
  group_by(., participant, target) %>%
  mutate(., time_zero = onset_pupil(bin, t_onset, event = c("TRUE"))) %>%
  ungroup(.)
  
# Load verbal WM
dem <- read_csv(here("data", "pupurri_analysis.csv"))
dem <- dem %>%
  select(., participant,DELE, percent_l2_week)
  
dem$participant <- tolower(dem$participant)
dem$DELE <- as.numeric(dem$DELE)

  
# Add verbal wm score to eyetracking data frame
stress_50 <- merge(x = stress_50, y = dem, by = "participant", all.x=TRUE)


# Create L1 column
stress_50 <- separate(stress_50,
                    col = group,
                    into = c("prof", "l1"),
                    sep = 1,
                    remove = FALSE)
  

stress_50$l1 <- str_replace(stress_50$l1, "es", "en")
stress_50$l1 <- str_replace(stress_50$l1, "ms", "ma")
stress_50$l1 <- str_replace(stress_50$l1, "on", "es")


#stress_50$DELE[is.na(stress_50$DELE) & stress_50$l1 == 'es'] <- 56
#stress_50$percent_l2_week[is.na(stress_50$percent_l2_week) & stress_50$l1 == 'es'] <- 0

# stress_50 %<>% filter(l1 != 'ma')
# # How much data we lose by selecting only accurate trials
# sum( ( stress_50$ACCURACY == 0 ) / length( stress_50$ACCURACY ) )
# # 0

 

# change name of .csv if trigger checked different
write_csv(stress_50, here("data", "clean", "stress_50ms_allparticipants.csv"))

# -----------------------------------------------------------------------------

stress50 <- read_csv(here("data", "clean", "stress_50ms_allparticipants.csv"))

stress50$cond <- factor(stress50$cond, levels = c("1", "2"), 
                        labels = c("Paroxytone/Present", "Oxytone/Preterit"))

# Test plot
stress50 %>%
  filter(time_zero > -10 & time_zero < 12 & l1 != 'ma') %>%
  ggplot(., aes(x = time_zero, y = target_prop, color = l1)) +
  facet_grid(cond ~ .) +
  geom_vline(xintercept = 4, lty = 3) +
  geom_hline(yintercept = 0.5, lty = 3) +
  stat_summary(fun.y = mean, geom = "line") +
  ggtitle("Time course per verbal tense") +
  xlab("Time in 50 ms bins") +
  ylab("Proportion of fixations on target") +
  scale_color_discrete(name="Group")


stress50 %>%
  filter(time_zero > -10 & time_zero < 12 &l1 != 'ma') %>%
  ggplot(., aes(x = time_zero, y = target_prop, color = cond)) +
  facet_grid(l1 ~ .) +
  geom_vline(xintercept = 4, lty = 3) +
  geom_hline(yintercept = 0.5, lty = 3) +
  stat_summary(fun.y = mean, geom = "line") +
  ggtitle("Time course per verbal tense") +
  xlab("Time in 50 ms bins") +
  ylab("Proportion of fixations on target") +
  scale_color_discrete(name="Condition")

stress50$l1_letters <- factor(stress50$l1, levels = c("en", "es"), 
                        labels = c("English speakers", "Spanish speakers"))


timecourse_en <- stress50 %>%
  filter(time_zero > -10 & time_zero < 10 & l1_letters != 'ma') %>%
  ggplot(., aes(x = time_zero, y = target_prop, fill = cond, color = cond)) +
  facet_grid(l1_letters ~ .) +
  geom_vline(xintercept = 4, lty = 3) +
  geom_hline(yintercept = 0.5, lty = 3) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(fun.data = mean_cl_boot, geom = 'pointrange', size = 0.5,
               stroke = 0.5, pch = 21) +
  xlab("Time relative to offset of verbs' initial syllable (ms)") +
  ylab("Proportion of fixations on the target") +
  labs(caption = "Mean +/- 95% CI") +
  scale_x_continuous(breaks = c(-8, -6, -4, -2, 0, 2, 4, 6, 8),
                     labels = c("-400", "-300", "-200", "-100", "0", "100", '200', "300", "400")) +
  scale_color_discrete(name="Stress condition") +
  scale_fill_discrete(name = 'Stress condition') +
  theme_grey(base_size = 10, base_family = "Times") +
  theme(legend.position = 'bottom')

ggsave('timecourse_en.png',
       plot = timecourse_en, dpi = 600, device = "png",
       path = here("figs", "use_prof"),
       height = 4, width = 4.5, units = 'in')


timecourse_simple <- stress50 %>%
  filter(time_zero > -10 & time_zero < 10 & l1_letters != 'ma') %>%
  mutate(., l1_letters = fct_relevel(l1_letters, "Spanish speakers")) %>%
  ggplot(., aes(x = time_zero, y = target_prop)) +
  facet_grid(l1_letters ~ cond) +
  geom_vline(xintercept = 4, lty = 3) +
  geom_hline(yintercept = 0.5, lty = 3) +
  stat_summary(fun.y = mean, geom = "line") +
  stat_summary(fun.data = mean_cl_boot, geom = 'pointrange', size = 0.5,
               stroke = 0.5, pch = 21) +
  xlab("Time relative to offset of verbs' initial syllable (ms)") +
  ylab("Proportion of fixations on the target") +
  labs(caption = "Mean +/- 95% CI") +
  scale_x_continuous(breaks = c(-8, -6, -4, -2, 0, 2, 4, 6, 8),
                     labels = c("-400", "-300", "-200", "-100", "0", "100", '200', "300", "400")) +
  #scale_color_discrete(name="Stress condition") +
  #scale_fill_discrete(name = 'Stress condition') +
  theme_grey(base_size = 10, base_family = "Times") #+
  #theme(legend.position = 'bottom')
  
ggsave('timecourse_simple.png',
       plot = timecourse_simple, dpi = 600, device = "png",
       path = here("figs", "use_prof"),
       height = 3, width = 4.5, units = 'in')



